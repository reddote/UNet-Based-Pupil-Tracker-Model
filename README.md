## ğŸ‘ï¸ eNetPupilTracker: U-Net-Based Pupil Segmentation System

**eNetPupilTracker** is a deep learning-based framework for pupil detection and segmentation. It uses a customized **U-Net384x288** architecture optimized for fast and accurate performance, suitable for real-time applications.

---

### ğŸ“ Model Overview

* **Architecture:** U-Net with 3Ã—3 kernels
* **Input Size:** `384 Ã— 288 Ã— 3` (RGB)
* **Output:** 2-class segmentation (e.g. pupil / background)
* **Post-processing:** Conv + ReLU + Conv refinement

---

### ğŸ“ Project Structure

```
eNetPupilTracker/
â”œâ”€â”€ Model/
â”‚   â”œâ”€â”€ unet_model.py            # U-Net model definition
â”‚   â”œâ”€â”€ gaze_dataset.py          # Dataset loader
â”‚   â””â”€â”€ OldModel/
â”‚       â””â”€â”€ efficient_b0.py      # (legacy model, unused)
â”‚
â”œâ”€â”€ Utils/
â”‚   â”œâ”€â”€ draw_eye.py              # Visualization tools
â”‚   â”œâ”€â”€ file_controller.py       # File navigation and logic
â”‚   â”œâ”€â”€ file_writer.py           # Prediction/image saving tools
â”‚   â””â”€â”€ find_pupil.py            # Pupil center metrics
â”‚
â”œâ”€â”€ output_frames/               # Input RGB images (organized in folders)
â”œâ”€â”€ segmentation/                # Ground truth segmentation labels
â”œâ”€â”€ predict/                     # Test images used for evaluating model accuracy
â”‚
â”œâ”€â”€ environment.yml              # Conda environment specification
â”œâ”€â”€ v2_main.py                   # âœ… Latest main script (use this)
â”œâ”€â”€ main.py                      # âŒ Legacy version (deprecated)
â”œâ”€â”€ main_test.py                 # Evaluation script
â”œâ”€â”€ test_model.py                # Model testing utilities
â”œâ”€â”€ log.txt                      # Log file
â””â”€â”€ .gitignore
```

---

### âš™ï¸ Environment Setup

```bash
conda env create -f environment.yml
conda activate enetpupil
```

---

### ğŸš€ Usage

#### ğŸ”¹ Run Inference / Evaluation (latest version)

```bash
python v2_main.py
```

This script:

* Loads input images from `output_frames/`
* Loads ground truth segmentation labels from `segmentation/`
* Uses test images in `predict/` for model accuracy checks
* Outputs segmentation predictions and pupil center metrics

#### ğŸ”¹ Evaluate model (optional)

```bash
python main_test.py
```

---

### ğŸ“Š Evaluation Metrics

* Dice Coefficient
* IoU (Intersection over Union)
* Precision & Recall
* Pupil center localization error (`find_pupil.py`)

---

### ğŸ§  Model Architecture Summary

| Stage         | Channels | Size (HxW) | Description                    |
| ------------- | -------- | ---------- | ------------------------------ |
| Input Image   | 3        | 384Ã—288    | RGB input                      |
| Stem          | 16       | 384Ã—288    | Initial ConvBlock              |
| Encoder 1     | 32       | 192Ã—144    | ConvBlock + Downsampling       |
| Encoder 2     | 64       | 96Ã—72      | ConvBlock + Downsampling       |
| Encoder 3     | 128      | 48Ã—36      | ConvBlock + Downsampling       |
| Encoder 4     | 256      | 24Ã—18      | ConvBlock + Downsampling       |
| Bottleneck    | 512      | 24Ã—18      | Deepest layer                  |
| Decoder 4     | 256      | 48Ã—36      | Upsample + Skip x4 + ConvBlock |
| Decoder 3     | 128      | 96Ã—72      | Upsample + Skip x3 + ConvBlock |
| Decoder 2     | 64       | 192Ã—144    | Upsample + Skip x2 + ConvBlock |
| Decoder 1     | 32       | 384Ã—288    | Upsample + Skip x1 + ConvBlock |
| Final Conv    | 2        | 384Ã—288    | 1Ã—1 Conv2D (2 classes)         |
| Output Refine | 2        | 384Ã—288    | Conv + ReLU + Conv             |

---

### âœ… Notes

* Use **`v2_main.py`** as the primary execution script.
* Segmentation masks (ground truth) must be stored in the `segmentation/` folder.
* Input image folders are inside `output_frames/`.
* Test image predictions (visual output) will appear in `predict/`.
